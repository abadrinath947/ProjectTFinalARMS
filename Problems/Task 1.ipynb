{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Advanced MNIST Classification\n",
    "\n",
    "The first task is to modify the convolutional neural network used in the previous section for the MNIST dataset. You are free to tweak any parameters including the number and type of layers, the order of the layers, the addition of other types of layers, the loss function, and optimization algorithm.\n",
    "\n",
    "The goal is to achieve 99.3% test accuracy with your model. You should split the current training set into a separate validation set and new training set.\n",
    "\n",
    "Here are some pointers to get you started:\n",
    "* Convolutional \"spam\" may not always work. Try a pooling layer after a set of convolutional layers, but don't use too many pooling layers since the MNIST dataset has low-dimensional images.\n",
    "* If you find yourself to be performing poorly on the validation dataset, you may be overfitting. Dropout layers zero out a fraction of the total parameters forcefully randomly; it can be thought of as a \"random Lasso\" form of regularization. Note that Dropout layers should not be used near the output layer of a network. Why?\n",
    "* A combination of the first and second model we created could be useful.\n",
    "* Your model needs to use ['accuracy'] as the only metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary Libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, Input, MaxPooling2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('mnist.npz')\n",
    "\n",
    "# load pre-decided train and test data\n",
    "X_train, y_train = data['x_train'], data['y_train']\n",
    "X_test, y_test = data['x_test'], data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to change the below lines, they are provided as skeleton code\n",
    "X_train_norm = X_train / 255\n",
    "X_test_norm = X_test / 255\n",
    "\n",
    "# what does the following do? look it up in the Keras documentation!\n",
    "y_train = keras.utils.to_categorical(y_train, ...)\n",
    "y_test = keras.utils.to_categorical(y_test, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "...\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(...)\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(..., ..., verbose = 0)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", acc)"
   ]
  },
   {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a visualization showing our model's efficacy on different digits",
    "plt.plot(...)\n",
    "print(\"Accuracy per digit:\", ...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

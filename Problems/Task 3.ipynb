{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "The provided UNetCNN.py contains a U-Net architecture convolutional neural network, which was originally used for biomedical image segmenation. \n",
    "\n",
    "Our goal is not to necessarily fully understand the reason behind the implementation, but it will be to explain and analyze the features of the network that have thus far been analyzed. Using the techniques from the analysis in the notes and the walkthrough of the creation of the CNN in Keras, answer the following questions.\n",
    "\n",
    "##### (a) Draw a diagram of the convolutional neural network provided in the code. Note that this model uses the functional model, which essentially behaves similarly to a linked list of layers. Refer to the note for examples on how to implement and reason with these models.\n",
    "\n",
    "#####  (b) Discuss a potential reason why the number of filters stays the same with each convolution in the first half of the model. Why do we implement pooling in the model?\n",
    "\n",
    "(YOUR ANSWER HERE)\n",
    "\n",
    "#####  (c) What could be a side effect of pooling too much in this model?\n",
    "\n",
    "(YOUR ANSWER HERE)\n",
    "\n",
    "#####  (d) Find the depth of this model. Consider one convolutional layer as one layer as opposed to the combination of convolutional layers and pooling layers as one layer.\n",
    "\n",
    "(YOUR ANSWER HERE)\n",
    "\n",
    "#####  (e) What purpose could the calls to concatenate serve? What kinds of layers are we concatenating with each other?\n",
    "\n",
    "(YOUR ANSWER HERE)\n",
    "\n",
    "##### (f) What kind of activation function is most prevalent? Is this typical or atypical of a convolutional neural network?\n",
    "\n",
    "(YOUR ANSWER HERE)\n",
    "\n",
    "##### (g) Discuss why this Keras model utilizes a Dropout layer and what potential side effects may be.\n",
    "\n",
    "(YOUR ANSWER HERE)\n",
    "\n",
    "##### (h) Why do we use a sigmoid activation function near the end of the network? How is this related to the normalization technique that is employed?\n",
    "\n",
    "(YOUR ANSWER HERE)\n",
    "\n",
    "##### (i) Discuss potential improvements to the model or any red flags.\n",
    "\n",
    "(YOUR ANSWER HERE)\n",
    "\n",
    "##### (j) Run the model. What is the test accuracy? Why does this make sense?\n",
    "\n",
    "(YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, UpSampling2D, concatenate, Dropout, Cropping2D\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one-hot encode to make this a classification task \n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_test = keras.utils.to_categorical(Y_test, 10)\n",
    "\n",
    "# (x, y, #channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "def get_crop_shape(target, refer):\n",
    "    \"\"\"From StackExchange question\"\"\"\n",
    "    # width, the 3rd dimension\n",
    "    cw = (target.get_shape()[2] - refer.get_shape()[2])\n",
    "    assert (cw >= 0)\n",
    "    if cw % 2 != 0:\n",
    "        cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "    else:\n",
    "        cw1, cw2 = int(cw/2), int(cw/2)\n",
    "    # height, the 2nd dimension\n",
    "    ch = (target.get_shape()[1] - refer.get_shape()[1])\n",
    "    assert (ch >= 0)\n",
    "    if ch % 2 != 0:\n",
    "        ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "    else:\n",
    "        ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "    return (ch1, ch2), (cw1, cw2)\n",
    "\n",
    "# downwards\n",
    "inp = keras.Input(shape = (28, 28, 1))\n",
    "c1 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(inp)\n",
    "c1 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(c1)\n",
    "# can comment next line and uncomment the following line for uncompressed\n",
    "inter = MaxPooling2D((2, 2))(c1)\n",
    "# inter = c1\n",
    "c2 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(inter)\n",
    "c2 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(c2)\n",
    "# can comment next line and uncomment the following line for uncompressed\n",
    "inter = MaxPooling2D((2, 2))(inter)\n",
    "inter = Dropout(0.5)(inter)\n",
    "# inter = c2\n",
    "inter = Conv2D(32, (3, 3), activation = 'relu')(inter)\n",
    "inter = Conv2D(32, (3, 3), activation = 'relu')(inter)\n",
    "\n",
    "# upwards\n",
    "inter = UpSampling2D((2, 2))(inter)\n",
    "c2_crop = Cropping2D(cropping=get_crop_shape(c2, inter)[0], data_format = \"channels_last\")(c2)\n",
    "inter = concatenate([inter, c2_crop])\n",
    "inter = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(inter)\n",
    "inter = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(inter)\n",
    "inter = UpSampling2D((2, 2))(inter)\n",
    "c1_crop = Cropping2D(cropping=get_crop_shape(c1, inter)[0], data_format = \"channels_last\")(c1)\n",
    "inter = concatenate([inter, c1_crop])\n",
    "inter = Conv2D(32, (3, 3), activation = 'relu')(inter)\n",
    "inter = Conv2D(32, (3, 3), activation = 'relu')(inter)\n",
    "inter = Conv2D(1, (1, 1), activation = 'sigmoid')(inter)\n",
    "out = Flatten()(inter)\n",
    "# softmax outperformed every other activation fn here\n",
    "out = Dense(32, activation = 'relu')(out)\n",
    "out = Dense(10, activation = 'softmax')(out)\n",
    "\n",
    "# softmax + binary CE > sigmoid + binary CE >>>>> anything + categ CE\n",
    "model = keras.Model(inputs=inp, outputs=out, name=\"mnist_model\")\n",
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 32, epochs = 12, validation_split = 0.2)\n",
    "\n",
    "print(model.evaluate(X_test, Y_test, verbose=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
